{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Mayda In_class_exercise_09.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ugf2oWMduY6J"
      },
      "source": [
        "# **The ninth in-class-exercise (20 points in total, 4/16/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZppYCLouY6M"
      },
      "source": [
        "The purpose of the exercise is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
        "\n",
        "The dataset can be download from here: https://github.com/unt-iialab/info5731_spring2021/blob/main/class_exercises/exercise09_datacollection.zip. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
        "\n",
        "Algorithms:\n",
        "\n",
        "(1) MultinominalNB\n",
        "\n",
        "(2) SVM \n",
        "\n",
        "(3) KNN \n",
        "\n",
        "(4) Decision tree\n",
        "\n",
        "(5) Random Forest\n",
        "\n",
        "(6) XGBoost\n",
        "\n",
        "Evaluation measurement:\n",
        "\n",
        "(1) Accuracy\n",
        "\n",
        "(2) Recall\n",
        "\n",
        "(3) Precison \n",
        "\n",
        "(4) F-1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmScS8tTuY6O"
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "#importing libraries needed\n",
        "\n",
        "import pandas as pd \n",
        "import re \n",
        "import nltk \n",
        "from nltk.corpus import stopwords \n",
        "from nltk.stem.porter import PorterStemmer \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhof-YA8vEps"
      },
      "source": [
        "\n",
        "#Loading Train and Test data\n",
        "\n",
        "my_data_train=pd.read_fwf(\"/content/stsa-train.txt\", header=None)\n",
        "my_data_train= pd.DataFrame(my_data_train)\n",
        "my_data_test=pd.read_fwf(\"/content/stsa-test.txt\", header=None)\n",
        "my_data_test= pd.DataFrame(my_data_test)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU8DnodIvG_h"
      },
      "source": [
        "#Now splitting my_data_train into training and validation data\n",
        "\n",
        "del my_data_train[2]\n",
        "my_data_train = my_data_train.rename(columns={0: \"Review\", 1: \"Text\"})\n",
        "del my_data_test[2]\n",
        "del my_data_test[3]\n",
        "my_data_test = my_data_test.rename(columns={0: \"Review\", 1: \"Text\"})\n",
        "x_train, x_validate, y_train, y_validate = sklearn.model_selection.train_test_split(my_data_train['Text'], my_data_train['Review'], train_size=0.8, test_size=0.2)\n",
        "x_train = x_train.to_numpy()\n",
        "y_train = y_train.to_numpy()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm6wxgjwvNk5"
      },
      "source": [
        "# Defining K-fold\n",
        "\n",
        "my_kf = KFold(n_splits=10)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnisJTr9vOpA"
      },
      "source": [
        "#MultinominalNB\n",
        "pln = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', MultinomialNB())])\n",
        "for train_index, test_index in my_kf.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "    MNB_algorithm = pln.fit(x_train_k, y_train_k)\n",
        "pred_validate = MNB_algorithm.predict(x_validate)\n",
        "validation = {'Actual': y_validate, 'Predicted': pred_validate}\n",
        "validation_df = pd.DataFrame(validation, columns = ['Actual', 'Predicted'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_0PTzJCvSml",
        "outputId": "e6de1900-403d-432e-ef56-1d3e0fbf730a"
      },
      "source": [
        "#Evaluation\n",
        "\n",
        "my_final = MNB_algorithm.predict(my_data_test['Text'])\n",
        "print('Accuracy of MultinomialNB :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('Recall of MultinomialNB :', (recall_score(my_data_test['Review'], my_final)*100))\n",
        "print('Precision of MultinomialNB :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('F1-score of MultinomialNB :', (f1_score(my_data_test['Review'], my_final, average='macro')*100))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of MultinomialNB : 80.45030203185063\n",
            "Recall of MultinomialNB : 88.11881188118812\n",
            "Precision of MultinomialNB : 80.45030203185063\n",
            "F1-score of MultinomialNB : 80.33901965018356\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uShaNVMavW6X"
      },
      "source": [
        "#SVM\n",
        "pln = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', LinearSVC())])\n",
        "for train_index, test_index in my_kf.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "    SVM_algorithm = pln.fit(x_train_k, y_train_k)\n",
        "pred_validate = SVM_algorithm.predict(x_validate)\n",
        "validation = {'Actual': y_validate, 'Predicted': pred_validate}\n",
        "validation_df = pd.DataFrame(validation, columns = ['Actual', 'Predicted'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn-qn7bXvZ7H",
        "outputId": "d2932e9d-e3d4-4ce3-f1b9-ebec3d68e930"
      },
      "source": [
        "my_final = SVM_algorithm.predict(my_data_test['Text'])\n",
        "print(' Accuracy of SVM :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('Recall of SVM :', (recall_score(my_data_test['Review'], my_final)*100))\n",
        "print(' Precision of SVM :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('F1-score of SVM :', (f1_score(my_data_test['Review'], my_final, average='macro')*100))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy of SVM : 80.12081274025262\n",
            "Recall of SVM : 83.27832783278328\n",
            " Precision of SVM : 80.12081274025262\n",
            "F1-score of SVM : 80.10266174386118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqNV-LaKvjEO"
      },
      "source": [
        "#KNN\n",
        "pln = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', KNeighborsClassifier())])\n",
        "for train_index, test_index in my_kf.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "    KNN_algorithm = pln.fit(x_train_k, y_train_k)\n",
        "pred_validate = KNN_algorithm.predict(x_validate)\n",
        "validation = {'Actual': y_validate, 'Predicted': pred_validate}\n",
        "validation_df = pd.DataFrame(validation, columns = ['Actual', 'Predicted'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPy6m-gHvoSa",
        "outputId": "9ca0f441-4b36-4142-9ae0-a54a9e1e1955"
      },
      "source": [
        "#Evaluation of KNN\n",
        "my_final = KNN_algorithm.predict(my_data_test['Text'])\n",
        "print(' Accuracy of KNN :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('Recall of KNN :', (recall_score(my_data_test['Review'], my_final)*100))\n",
        "print(' Precision of KNN :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('F1-score of KNN :', (f1_score(my_data_test['Review'], my_final, average='macro')*100))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy of KNN : 72.26798462383306\n",
            "Recall of KNN : 80.19801980198021\n",
            " Precision of KNN : 72.26798462383306\n",
            "F1-score of KNN : 72.09832163032783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sM3bbPDvsmT"
      },
      "source": [
        "#Random Forest:\n",
        "pln = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', RandomForestClassifier(n_estimators=100))])\n",
        "for train_index, test_index in my_kf.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "    RF_algorithm = pln.fit(x_train_k, y_train_k)\n",
        "pred_validate = RF_algorithm.predict(x_validate)\n",
        "validation = {'Actual': y_validate, 'Predicted': pred_validate}\n",
        "validation_df = pd.DataFrame(validation, columns = ['Actual', 'Predicted'])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuS3kuNEvwma",
        "outputId": "bc291478-593d-4245-e7fd-99e2f082703d"
      },
      "source": [
        "#Evaluation\n",
        "my_final = RF_algorithm.predict(my_data_test['Text'])\n",
        "print(' Accuracy of Random Forest :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('Recall of Random Forest :', (recall_score(my_data_test['Review'], my_final)*100))\n",
        "print(' Precision of Random Forest :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('F1-score of Random Forest :', (f1_score(my_data_test['Review'], my_final, average='macro')*100))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy of Random Forest : 71.44426139483801\n",
            "Recall of Random Forest : 75.35753575357535\n",
            " Precision of Random Forest : 71.44426139483801\n",
            "F1-score of Random Forest : 71.4032035949844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHv-Bpk0v0xy",
        "outputId": "e0a6ec1c-91a0-4483-b6a0-36b571cdd0f9"
      },
      "source": [
        "#XGBoost:\n",
        "pln = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', GradientBoostingClassifier(n_estimators=20,verbose=2))])\n",
        "for train_index, test_index in my_kf.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "    \n",
        "    XGB_algorithm = pln.fit(x_train_k, y_train_k)\n",
        "pred_validate = XGB_algorithm.predict(x_validate)\n",
        "validation = {'Actual': y_validate, 'Predicted': pred_validate}\n",
        "validation_df = pd.DataFrame(validation, columns = ['Actual', 'Predicted'])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3753            0.66s\n",
            "         2           1.3674            0.62s\n",
            "         3           1.3606            0.58s\n",
            "         4           1.3547            0.56s\n",
            "         5           1.3495            0.53s\n",
            "         6           1.3448            0.50s\n",
            "         7           1.3405            0.46s\n",
            "         8           1.3367            0.42s\n",
            "         9           1.3328            0.38s\n",
            "        10           1.3288            0.34s\n",
            "        11           1.3251            0.31s\n",
            "        12           1.3216            0.27s\n",
            "        13           1.3181            0.24s\n",
            "        14           1.3147            0.20s\n",
            "        15           1.3115            0.17s\n",
            "        16           1.3082            0.14s\n",
            "        17           1.3055            0.10s\n",
            "        18           1.3025            0.07s\n",
            "        19           1.2993            0.03s\n",
            "        20           1.2962            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3755            0.65s\n",
            "         2           1.3682            0.62s\n",
            "         3           1.3617            0.60s\n",
            "         4           1.3559            0.55s\n",
            "         5           1.3508            0.52s\n",
            "         6           1.3457            0.49s\n",
            "         7           1.3414            0.45s\n",
            "         8           1.3373            0.41s\n",
            "         9           1.3330            0.38s\n",
            "        10           1.3294            0.35s\n",
            "        11           1.3252            0.31s\n",
            "        12           1.3217            0.28s\n",
            "        13           1.3189            0.24s\n",
            "        14           1.3154            0.21s\n",
            "        15           1.3118            0.17s\n",
            "        16           1.3082            0.14s\n",
            "        17           1.3056            0.10s\n",
            "        18           1.3033            0.07s\n",
            "        19           1.3004            0.03s\n",
            "        20           1.2971            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3755            0.64s\n",
            "         2           1.3676            0.60s\n",
            "         3           1.3609            0.57s\n",
            "         4           1.3549            0.53s\n",
            "         5           1.3496            0.50s\n",
            "         6           1.3442            0.47s\n",
            "         7           1.3396            0.43s\n",
            "         8           1.3352            0.40s\n",
            "         9           1.3306            0.36s\n",
            "        10           1.3265            0.33s\n",
            "        11           1.3224            0.30s\n",
            "        12           1.3184            0.27s\n",
            "        13           1.3146            0.23s\n",
            "        14           1.3110            0.20s\n",
            "        15           1.3078            0.17s\n",
            "        16           1.3047            0.13s\n",
            "        17           1.3022            0.10s\n",
            "        18           1.2990            0.07s\n",
            "        19           1.2961            0.03s\n",
            "        20           1.2928            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3761            0.61s\n",
            "         2           1.3690            0.58s\n",
            "         3           1.3630            0.55s\n",
            "         4           1.3574            0.52s\n",
            "         5           1.3525            0.49s\n",
            "         6           1.3482            0.45s\n",
            "         7           1.3435            0.43s\n",
            "         8           1.3391            0.39s\n",
            "         9           1.3355            0.36s\n",
            "        10           1.3321            0.32s\n",
            "        11           1.3283            0.29s\n",
            "        12           1.3245            0.26s\n",
            "        13           1.3208            0.23s\n",
            "        14           1.3180            0.19s\n",
            "        15           1.3148            0.16s\n",
            "        16           1.3116            0.13s\n",
            "        17           1.3090            0.10s\n",
            "        18           1.3058            0.06s\n",
            "        19           1.3026            0.03s\n",
            "        20           1.3002            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3767            0.63s\n",
            "         2           1.3697            0.60s\n",
            "         3           1.3636            0.56s\n",
            "         4           1.3586            0.52s\n",
            "         5           1.3539            0.49s\n",
            "         6           1.3498            0.45s\n",
            "         7           1.3456            0.42s\n",
            "         8           1.3415            0.39s\n",
            "         9           1.3378            0.36s\n",
            "        10           1.3339            0.33s\n",
            "        11           1.3306            0.29s\n",
            "        12           1.3271            0.26s\n",
            "        13           1.3243            0.23s\n",
            "        14           1.3214            0.20s\n",
            "        15           1.3181            0.17s\n",
            "        16           1.3154            0.13s\n",
            "        17           1.3126            0.10s\n",
            "        18           1.3095            0.07s\n",
            "        19           1.3065            0.03s\n",
            "        20           1.3035            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3751            0.66s\n",
            "         2           1.3675            0.61s\n",
            "         3           1.3607            0.56s\n",
            "         4           1.3550            0.52s\n",
            "         5           1.3490            0.49s\n",
            "         6           1.3441            0.47s\n",
            "         7           1.3393            0.43s\n",
            "         8           1.3348            0.40s\n",
            "         9           1.3308            0.36s\n",
            "        10           1.3270            0.33s\n",
            "        11           1.3229            0.29s\n",
            "        12           1.3195            0.26s\n",
            "        13           1.3159            0.23s\n",
            "        14           1.3118            0.20s\n",
            "        15           1.3089            0.16s\n",
            "        16           1.3058            0.13s\n",
            "        17           1.3018            0.10s\n",
            "        18           1.2989            0.06s\n",
            "        19           1.2957            0.03s\n",
            "        20           1.2925            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3758            0.68s\n",
            "         2           1.3682            0.62s\n",
            "         3           1.3620            0.58s\n",
            "         4           1.3562            0.53s\n",
            "         5           1.3511            0.49s\n",
            "         6           1.3467            0.46s\n",
            "         7           1.3426            0.43s\n",
            "         8           1.3389            0.39s\n",
            "         9           1.3348            0.36s\n",
            "        10           1.3312            0.33s\n",
            "        11           1.3271            0.29s\n",
            "        12           1.3239            0.26s\n",
            "        13           1.3210            0.23s\n",
            "        14           1.3179            0.20s\n",
            "        15           1.3156            0.17s\n",
            "        16           1.3122            0.13s\n",
            "        17           1.3096            0.10s\n",
            "        18           1.3068            0.07s\n",
            "        19           1.3039            0.03s\n",
            "        20           1.3012            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3767            0.63s\n",
            "         2           1.3692            0.60s\n",
            "         3           1.3630            0.58s\n",
            "         4           1.3571            0.54s\n",
            "         5           1.3518            0.51s\n",
            "         6           1.3471            0.47s\n",
            "         7           1.3423            0.44s\n",
            "         8           1.3382            0.40s\n",
            "         9           1.3347            0.37s\n",
            "        10           1.3311            0.33s\n",
            "        11           1.3278            0.29s\n",
            "        12           1.3240            0.26s\n",
            "        13           1.3212            0.23s\n",
            "        14           1.3186            0.20s\n",
            "        15           1.3152            0.16s\n",
            "        16           1.3127            0.13s\n",
            "        17           1.3092            0.10s\n",
            "        18           1.3055            0.07s\n",
            "        19           1.3020            0.03s\n",
            "        20           1.2999            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3761            0.67s\n",
            "         2           1.3686            0.65s\n",
            "         3           1.3622            0.60s\n",
            "         4           1.3565            0.56s\n",
            "         5           1.3514            0.51s\n",
            "         6           1.3465            0.48s\n",
            "         7           1.3423            0.44s\n",
            "         8           1.3379            0.41s\n",
            "         9           1.3337            0.37s\n",
            "        10           1.3301            0.34s\n",
            "        11           1.3265            0.30s\n",
            "        12           1.3232            0.27s\n",
            "        13           1.3196            0.23s\n",
            "        14           1.3165            0.20s\n",
            "        15           1.3135            0.17s\n",
            "        16           1.3111            0.13s\n",
            "        17           1.3076            0.10s\n",
            "        18           1.3046            0.07s\n",
            "        19           1.3016            0.03s\n",
            "        20           1.2991            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3756            0.63s\n",
            "         2           1.3680            0.62s\n",
            "         3           1.3616            0.60s\n",
            "         4           1.3560            0.55s\n",
            "         5           1.3508            0.51s\n",
            "         6           1.3461            0.47s\n",
            "         7           1.3419            0.43s\n",
            "         8           1.3377            0.40s\n",
            "         9           1.3331            0.36s\n",
            "        10           1.3290            0.33s\n",
            "        11           1.3258            0.29s\n",
            "        12           1.3220            0.26s\n",
            "        13           1.3191            0.23s\n",
            "        14           1.3156            0.20s\n",
            "        15           1.3124            0.16s\n",
            "        16           1.3091            0.13s\n",
            "        17           1.3051            0.10s\n",
            "        18           1.3023            0.07s\n",
            "        19           1.2985            0.03s\n",
            "        20           1.2959            0.00s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBu4V-mpv4wD",
        "outputId": "1ce1f7a9-ed82-4404-a47c-5c4824a9494a"
      },
      "source": [
        "#Evaluation\n",
        "my_final = XGB_algorithm.predict(my_data_test['Text'])\n",
        "print(' Accuracy of XG Boost :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('Recall of XG Boost :', (recall_score(my_data_test['Review'], my_final)*100))\n",
        "print(' Precision of XG Boost :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('F1-score of XG Boost :', (f1_score(my_data_test['Review'], my_final, average='macro')*100))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy of XG Boost : 59.25315760571115\n",
            "Recall of XG Boost : 88.55885588558856\n",
            " Precision of XG Boost : 59.25315760571115\n",
            "F1-score of XG Boost : 55.46650055370985\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}